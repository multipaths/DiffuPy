{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute graph kernels in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:test\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import logging\n",
    "import scipy as sp\n",
    "from math import pi\n",
    "import sys\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.debug(\"test\")\n",
    "\n",
    "import os \n",
    "dir_path = os.path.dirname(os.path.realpath('__file__'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import kernel functions from diffuPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kernel functions a imported from the package. Despite this the functions implementation are in this notebook (final _imp in the function name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffupy.kernel import commute_time_kernel, p_step_kernel, inverse_cosine_kernel, diffusion_kernel, regularised_laplacian_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import example graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x1278a9048>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = nx.read_gml(dir_path+'/04_unit_testing/_graph.gml', label='id')\n",
    "G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_laplacian(G, normalized = False):\n",
    "    if nx.is_directed(G):\n",
    "        sys.exit('Graph must be undirected')\n",
    "        \n",
    "    if not normalized:\n",
    "        L = nx.laplacian_matrix(G).toarray()\n",
    "    else:\n",
    "        L = nx.normalized_laplacian_matrix(G).toarray()\n",
    "    \n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_diagonal_matrix(M, d):\n",
    "    for j, row in enumerate(M):\n",
    "        for i, x in enumerate(row):\n",
    "            if i==j:\n",
    "                M[j][i] = d[i]\n",
    "            else:\n",
    "                M[j][i] = x\n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_list_graph(graph):\n",
    "    return [v for k, v in nx.get_node_attributes(graph, 'name').items()]\n",
    "\n",
    "def get_label_id_mapping(matrix, labels_row, labels_col = None):\n",
    "    if not labels_col:\n",
    "        return {label: i for i, label in enumerate(labels_row)}\n",
    "    else:\n",
    "        return {label_row:{label_col: (j, i) for j, label_col in enumerate(labels_col)} for i, label_row in enumerate(labels_row)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Matrix:\n",
    "    def __init__(self, mat, name='', rows_labels=[], cols_labels=[], dupl=False, graph=None, **kw):\n",
    "        self.name = name\n",
    "        self._mat = np.array(mat)\n",
    "        self.rows_labels = rows_labels\n",
    "        self.cols_labels = cols_labels\n",
    "        \n",
    "        if graph:\n",
    "            self.rows_labels = get_label_list_graph(graph)\n",
    "        \n",
    "        elif dupl:\n",
    "            self.cols_labels = self.rows_labels\n",
    "        label_id_mapping = get_label_id_mapping(mat, rows_labels, cols_labels)\n",
    "\n",
    "    # Getters - setters\n",
    "    # Raw matrix (numpy array)\n",
    "    @property\n",
    "    def mat(self):\n",
    "        return self._mat\n",
    "    \n",
    "    @mat.setter\n",
    "    def mat(self, mat):\n",
    "        self._mat = mat\n",
    "\n",
    "    # Matrix title\n",
    "    def set_name(self, name):\n",
    "        self.name = name\n",
    "    \n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "\n",
    "    # Rows labels\n",
    "    def set_rows_labels(self, rows_labels):\n",
    "        self.rows_labels = list(rows_labels)\n",
    "    \n",
    "    def get_rows_labels(self):\n",
    "        return self.rows_labels\n",
    "    \n",
    "    # Columns labels\n",
    "    def set_col_labels(self, cols_labels):\n",
    "        self.cols_labels = list(cols_labels)\n",
    "    \n",
    "    def get_col_labels(self):\n",
    "        return self.cols_labels\n",
    "    \n",
    "    # From labels\n",
    "    def set_row_from_label(self, label, x):\n",
    "        i_row = self.label_id_mapping[label]\n",
    "        if isintance(i_row, dict):\n",
    "            i_row = i_row[label].values()[0][0]\n",
    "        self.mat[i_row] = x\n",
    "    \n",
    "    def get_row_from_label(self, label):\n",
    "        i_row = self.label_id_mapping[label]\n",
    "        if isintance(i_row, dict):\n",
    "            i_row = i_row[label].values()[0][0]\n",
    "        return self.mat[i_row]\n",
    "    \n",
    "    def set_col_from_label(self, label, x):\n",
    "        i_col = self.label_id_mapping[label]\n",
    "        if isintance(i_col, dict):\n",
    "            i_col = i_col[label].values()[0][0]\n",
    "        self.mat[:,i_col] = x\n",
    "\n",
    "    def get_col_from_label(self, label, x):\n",
    "        i_col = self.label_id_mapping[label]\n",
    "        if isintance(i_col, dict):\n",
    "            i_col = i_col[label].values()[0][0]\n",
    "        return self.mat[:,i_col]\n",
    "    \n",
    "    def set_from_labels(self, row_label, col_label, x):\n",
    "        self.mat[self.label_id_mapping[row_label][col_label]] = x\n",
    "    \n",
    "    def get_from_labels(self, row_label, col_label):\n",
    "        return self.mat[self.label_id_mapping[row_label][col_label]]\n",
    "    \n",
    "    def match_matrix(self):\n",
    "        return self.rows_labels\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"matrix %s \\n %s \\n row_labels \\n : %s \\n column_labels \\n : %s\" % (self.name, self.mat, self.rows_labels, self.cols_labels)\n",
    "    \n",
    "    \n",
    "class LaplacianMatrix(Matrix):\n",
    "    def __init__(self, graph, normalized = False, name=''):\n",
    "        l_mat = get_laplacian(graph, normalized)\n",
    "        Matrix.__init__(self, l_mat, name=name, graph=graph, dupl=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_labeled_matrix_to_nparray(path):\n",
    "    # Import matrix from csv file and remove headers\n",
    "    m = np.genfromtxt(path, delimiter=',')\n",
    "    return np.array([[x for x in a if ~np.isnan(x)] for a in m[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kernel_test(kernel_func, G, T):\n",
    "    M = kernel_func(G).mat\n",
    "    logging.info(' %s  \\n %s\\n', 'Computed matrix', M)\n",
    "    logging.info(' %s  \\n %s\\n', 'Test matrix', T)\n",
    "    # Assert rounded similarity (floating comma)\n",
    "    assert np.allclose(M, T)\n",
    "    logging.info(' Test '+ kernel_func.__name__ +' passed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commute time kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computes the conmute-time kernel, which is the expected time of going back and forth between a couple of nodes. If the network is connected, then the commute time kernel will be totally dense, therefore reflecting global properties of the network. For further details, see [Yen, 2007]. This kernel can be computed using both the unnormalised and normalised graph Laplacian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root: Computed matrix  \n",
      " [[ 0.13585449  0.01349958  0.00707249 ...  0.00140383 -0.00238913\n",
      "  -0.00211733]\n",
      " [ 0.01349958  0.09948265  0.00573008 ...  0.0325679  -0.00379415\n",
      "   0.00052156]\n",
      " [ 0.00707249  0.00573008  0.05223533 ... -0.00223114  0.01331363\n",
      "  -0.0036509 ]\n",
      " ...\n",
      " [ 0.00140383  0.0325679  -0.00223114 ...  0.39279541 -0.00579927\n",
      "  -0.00742603]\n",
      " [-0.00238913 -0.00379415  0.01331363 ... -0.00579927  0.37149228\n",
      "  -0.00921487]\n",
      " [-0.00211733  0.00052156 -0.0036509  ... -0.00742603 -0.00921487\n",
      "   0.35492096]]\n",
      "\n",
      "INFO:root: Test matrix  \n",
      " [[ 0.13585449  0.01349958  0.00707249 ...  0.00140383 -0.00238913\n",
      "  -0.00211733]\n",
      " [ 0.01349958  0.09948265  0.00573008 ...  0.0325679  -0.00379415\n",
      "   0.00052156]\n",
      " [ 0.00707249  0.00573008  0.05223533 ... -0.00223114  0.01331363\n",
      "  -0.0036509 ]\n",
      " ...\n",
      " [ 0.00140383  0.0325679  -0.00223114 ...  0.39279541 -0.00579927\n",
      "  -0.00742603]\n",
      " [-0.00238913 -0.00379415  0.01331363 ... -0.00579927  0.37149228\n",
      "  -0.00921487]\n",
      " [-0.00211733  0.00052156 -0.0036509  ... -0.00742603 -0.00921487\n",
      "   0.35492096]]\n",
      "\n",
      "INFO:root: Test commute_time_kernel_impl passed\n"
     ]
    }
   ],
   "source": [
    "def commute_time_kernel_impl(G, normalized = False):\n",
    "    # Apply pseudo-inverse (moore-penrose) of laplacian matrix\n",
    "    L = LaplacianMatrix(G, normalized)\n",
    "    L.mat = np.linalg.pinv(L.mat)\n",
    "    return L\n",
    "\n",
    "run_kernel_test(commute_time_kernel_impl, G, csv_labeled_matrix_to_nparray(dir_path+'/04_unit_testing/commuteTimeKernel.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diffusion kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computes the classical diffusion kernel that involves matrix exponentiation. It has a \"bandwidth\" parameter Ïƒ^2 that controls the extent of the spreading. Quoting [Smola, 2003]: K(x1,x2) can be visualized as the quantity of some substance that would accumulate at vertex x2 after a given amount of time if we injected the substance at vertex x1 and let it diffuse through the graph along the edges. This kernel can be computed using both the unnormalised and normalised graph Laplacian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-d376dda27216>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrun_kernel_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiffusion_kernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_labeled_matrix_to_nparray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/04_unit_testing/diffusionKernel.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-90-7f073ee0feba>\u001b[0m in \u001b[0;36mrun_kernel_test\u001b[0;34m(kernel_func, G, T)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_kernel_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' %s  \\n %s\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Computed matrix'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' %s  \\n %s\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Test matrix'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Assert rounded similarity (floating comma)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'mat'"
     ]
    }
   ],
   "source": [
    "def diffusion_kernel_imp(G, sigma2 = 1, normalized = True):    \n",
    "    EL = -sigma2/2*get_laplacian(G, normalized)\n",
    "    return sp.linalg.expm(EL)\n",
    "\n",
    "run_kernel_test(diffusion_kernel, G, csv_labeled_matrix_to_nparray(dir_path+'/04_unit_testing/diffusionKernel.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse cosine kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computes the inverse cosine kernel, which is based on a cosine transform on the spectrum of the normalized Laplacian matrix. Quoting [Smola, 2003]: the inverse cosine kernel treats lower complexity functions almost equally, with a significant reduction in the upper end of the spectrum. This kernel is computed using the normalised graph Laplacian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root: Computed matrix  \n",
      " [[ 6.89153644e-01  5.06788574e-02  3.42575829e-02 ... -4.17444129e-03\n",
      "  -2.22597740e-03 -2.38465091e-03]\n",
      " [ 5.06788574e-02  6.71392147e-01  2.20078787e-02 ...  8.97968412e-02\n",
      "  -2.01160492e-03 -4.58819509e-03]\n",
      " [ 3.42575829e-02  2.20078787e-02  6.63386784e-01 ... -3.09491030e-03\n",
      "   6.46799766e-02 -1.77647780e-03]\n",
      " ...\n",
      " [-4.17444129e-03  8.97968412e-02 -3.09491030e-03 ...  6.74893062e-01\n",
      "  -3.15696738e-04 -3.25294979e-04]\n",
      " [-2.22597740e-03 -2.01160492e-03  6.46799766e-02 ... -3.15696738e-04\n",
      "   6.83686983e-01 -6.82799209e-05]\n",
      " [-2.38465091e-03 -4.58819509e-03 -1.77647780e-03 ... -3.25294979e-04\n",
      "  -6.82799209e-05  6.92214032e-01]]\n",
      "\n",
      "INFO:root: Test matrix  \n",
      " [[ 6.89153644e-01  5.06788574e-02  3.42575829e-02 ... -4.17444129e-03\n",
      "  -2.22597740e-03 -2.38465091e-03]\n",
      " [ 5.06788574e-02  6.71392147e-01  2.20078787e-02 ...  8.97968412e-02\n",
      "  -2.01160492e-03 -4.58819509e-03]\n",
      " [ 3.42575829e-02  2.20078787e-02  6.63386784e-01 ... -3.09491030e-03\n",
      "   6.46799766e-02 -1.77647780e-03]\n",
      " ...\n",
      " [-4.17444129e-03  8.97968412e-02 -3.09491030e-03 ...  6.74893062e-01\n",
      "  -3.15696738e-04 -3.25294979e-04]\n",
      " [-2.22597740e-03 -2.01160492e-03  6.46799766e-02 ... -3.15696738e-04\n",
      "   6.83686983e-01 -6.82799209e-05]\n",
      " [-2.38465091e-03 -4.58819509e-03 -1.77647780e-03 ... -3.25294979e-04\n",
      "  -6.82799209e-05  6.92214032e-01]]\n",
      "\n",
      "INFO:root: Test inverse_cosine_kernel passed\n"
     ]
    }
   ],
   "source": [
    "def inverse_cosine_kernel_imp(G):    \n",
    "    # Decompose matrix (Singular Value Decomposition)\n",
    "    U, S, _ = np.linalg.svd(get_laplacian(G, normalized = True)*(pi/4))\n",
    "\n",
    "    return np.matmul(np.matmul(U, np.diag(np.cos(S))), np.transpose(U))\n",
    "    \n",
    "run_kernel_test(inverse_cosine_kernel, G, csv_labeled_matrix_to_nparray(dir_path+'/04_unit_testing/inverseCosineKernel.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## p Step Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computes the p-step random walk kernel. This kernel is more focused on local properties of the nodes, because random walks are limited in terms of length. Therefore, if p is small, only a fraction of the values K(x1,x2) will be non-null if the network is sparse [Smola, 2003]. The parameter a is a regularising term that is summed to the spectrum of the normalised Laplacian matrix, and has to be 2 or greater. The p-step kernels can be cheaper to compute and have been successful in biological tasks, see the benchmark in [Valentini, 2014].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root: Computed matrix  \n",
      " [[2.08076205 1.15956073 1.12628329 ... 0.3537027  0.22148895 0.20527764]\n",
      " [1.15956073 3.11445732 1.30505581 ... 1.39693131 0.22230188 0.38745453]\n",
      " [1.12628329 1.30505581 3.6974033  ... 0.37356627 1.06904579 0.26027947]\n",
      " ...\n",
      " [0.3537027  1.39693131 0.37356627 ... 2.7254085  0.10096354 0.08424824]\n",
      " [0.22148895 0.22230188 1.06904579 ... 0.10096354 2.24207215 0.03899635]\n",
      " [0.20527764 0.38745453 0.26027947 ... 0.08424824 0.03899635 1.79935198]]\n",
      "\n",
      "INFO:root: Test matrix  \n",
      " [[2.08076205 1.15956073 1.12628329 ... 0.3537027  0.22148895 0.20527764]\n",
      " [1.15956073 3.11445732 1.30505581 ... 1.39693131 0.22230188 0.38745453]\n",
      " [1.12628329 1.30505581 3.6974033  ... 0.37356627 1.06904579 0.26027947]\n",
      " ...\n",
      " [0.3537027  1.39693131 0.37356627 ... 2.7254085  0.10096354 0.08424824]\n",
      " [0.22148895 0.22230188 1.06904579 ... 0.10096354 2.24207215 0.03899635]\n",
      " [0.20527764 0.38745453 0.26027947 ... 0.08424824 0.03899635 1.79935198]]\n",
      "\n",
      "INFO:root: Test p_step_kernel passed\n"
     ]
    }
   ],
   "source": [
    "def p_step_kernel_imp(G, a = 2, p = 5):\n",
    "    minusL = -get_laplacian(G, normalized = True)\n",
    "    \n",
    "    # Not optimal but kept for clarity\n",
    "    # here we restrict to the normalised version, as the eigenvalues are\n",
    "    # between 0 and 2 -> restriction a >= 2\n",
    "    if a < 2:\n",
    "        sys.exit('Eigenvalues must be between 0 and 2')\n",
    "    if p < 0:\n",
    "        sys.exit('p must be greater than 0')\n",
    "                \n",
    "    M = set_diagonal_matrix(minusL, [x + a for x in np.diag(minusL)])\n",
    "\n",
    "    if p == 1: return M\n",
    "    \n",
    "    return np.linalg.matrix_power(M, p)\n",
    "\n",
    "run_kernel_test(p_step_kernel, G, csv_labeled_matrix_to_nparray(dir_path+'/04_unit_testing/pStepKernel.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularised Laplacian Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computes the regularised Laplacian kernel, which is a standard in biological networks. The regularised Laplacian kernel arises in numerous situations, such as the finite difference formulation of the diffusion equation and in Gaussian process estimation. Sticking to the heat diffusion model, this function allows to control the constant terms summed to the diagonal through add_diag, i.e. the strength of the leaking in each node. If a node has diagonal term of 0, it is not allowed to disperse heat. The larger the diagonal term of a node, the stronger the first order heat dispersion in it, provided that it is positive. Every connected component in the graph should be able to disperse heat, i.e. have at least a node i with add_diag[i] > 0. If this is not the case, the result diverges. More details on the parameters can be found in [Smola, 2003]. This kernel can be computed using both the unnormalised and normalised graph Laplacian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root: Computed matrix  \n",
      " [[0.12776984 0.01982103 0.01521483 ... 0.0096302  0.00799348 0.00802052]\n",
      " [0.01982103 0.09644469 0.01419031 ... 0.029662   0.00731632 0.00934891]\n",
      " [0.01521483 0.01419031 0.05718463 ... 0.00781676 0.01878348 0.00724993]\n",
      " ...\n",
      " [0.0096302  0.029662   0.00781676 ... 0.28378943 0.00583329 0.00537881]\n",
      " [0.00799348 0.00731632 0.01878348 ... 0.00583329 0.27568824 0.00469274]\n",
      " [0.00802052 0.00934891 0.00724993 ... 0.00537881 0.00469274 0.26924707]]\n",
      "\n",
      "INFO:root: Test matrix  \n",
      " [[0.12776984 0.01982103 0.01521483 ... 0.0096302  0.00799348 0.00802052]\n",
      " [0.01982103 0.09644469 0.01419031 ... 0.029662   0.00731632 0.00934891]\n",
      " [0.01521483 0.01419031 0.05718463 ... 0.00781676 0.01878348 0.00724993]\n",
      " ...\n",
      " [0.0096302  0.029662   0.00781676 ... 0.28378943 0.00583329 0.00537881]\n",
      " [0.00799348 0.00731632 0.01878348 ... 0.00583329 0.27568824 0.00469274]\n",
      " [0.00802052 0.00934891 0.00724993 ... 0.00537881 0.00469274 0.26924707]]\n",
      "\n",
      "INFO:root: Test regularised_laplacian_kernel passed\n"
     ]
    }
   ],
   "source": [
    "def regularised_laplacian_kernel_imp(G, sigma2 = 1, add_diag = 1, normalized = False):\n",
    "    L = get_laplacian(G, normalized)\n",
    "    RL = set_diagonal_matrix(sigma2*L, [x + add_diag for x in np.diag(L)])\n",
    "        \n",
    "    return np.linalg.inv(RL)\n",
    "\n",
    "run_kernel_test(regularised_laplacian_kernel, G, csv_labeled_matrix_to_nparray(dir_path+'/04_unit_testing/regularisedLaplacianKernel.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
